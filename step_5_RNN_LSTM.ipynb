{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UTwNkBtRj-MN",
    "outputId": "fdc948a5-5ae7-4124-e197-39f4ad657f61"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, SimpleRNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErU3zouFvpon"
   },
   "source": [
    "**Attempt 1: The shortened version of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/short_dataset.csv')\n",
    "reviews = df['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "tqt21P-2vyA2"
   },
   "outputs": [],
   "source": [
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(reviews)\n",
    "X = pad_sequences(X, maxlen=maxlen)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_changer(sentiment):\n",
    "    if sentiment == 'positive':\n",
    "        x = 1\n",
    "    else:\n",
    "        x = 0\n",
    "    return x\n",
    "sentiments = df['Sentiment'].apply(sent_changer)\n",
    "\n",
    "Le = LabelEncoder()\n",
    "\n",
    "y = Le.fit_transform(df['Sentiment'])\n",
    "y = to_categorical(sentiments, 2)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "6cwjkqkCv0KU"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4CqXUO-sPwY",
    "outputId": "ac16183c-ad55-4d0f-947c-238b5792a4f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 100)         500000    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 15)                6960      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 32        \n",
      "=================================================================\n",
      "Total params: 506,992\n",
      "Trainable params: 506,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 100))\n",
    "model.add(LSTM(15, dropout=0.3))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),'accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNHo9l7Tvtm7",
    "outputId": "a850cad3-e55f-4f38-f2ef-bddc6cf03344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "127/127 [==============================] - 25s 200ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6933 - val_accuracy: 0.4905\n",
      "Epoch 2/10\n",
      "127/127 [==============================] - 25s 195ms/step - loss: 0.6924 - accuracy: 0.5339 - val_loss: 0.6931 - val_accuracy: 0.5043\n",
      "Epoch 3/10\n",
      "127/127 [==============================] - 25s 195ms/step - loss: 0.6912 - accuracy: 0.5687 - val_loss: 0.6926 - val_accuracy: 0.5085\n",
      "Epoch 4/10\n",
      "127/127 [==============================] - 25s 196ms/step - loss: 0.6893 - accuracy: 0.5792 - val_loss: 0.6919 - val_accuracy: 0.5218\n",
      "Epoch 5/10\n",
      "127/127 [==============================] - 25s 199ms/step - loss: 0.6863 - accuracy: 0.5951 - val_loss: 0.6913 - val_accuracy: 0.5230\n",
      "Epoch 6/10\n",
      "127/127 [==============================] - 25s 201ms/step - loss: 0.6821 - accuracy: 0.6053 - val_loss: 0.6909 - val_accuracy: 0.5186\n",
      "Epoch 7/10\n",
      "127/127 [==============================] - 25s 201ms/step - loss: 0.6745 - accuracy: 0.6200 - val_loss: 0.6912 - val_accuracy: 0.5235\n",
      "Epoch 8/10\n",
      "127/127 [==============================] - 25s 200ms/step - loss: 0.6605 - accuracy: 0.6379 - val_loss: 0.6975 - val_accuracy: 0.5279\n",
      "Epoch 9/10\n",
      "127/127 [==============================] - 25s 197ms/step - loss: 0.6409 - accuracy: 0.6492 - val_loss: 0.7038 - val_accuracy: 0.5100\n",
      "Epoch 10/10\n",
      "127/127 [==============================] - 26s 207ms/step - loss: 0.6212 - accuracy: 0.6698 - val_loss: 0.7144 - val_accuracy: 0.5181\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TdOlx4W7cqZ"
   },
   "source": [
    "**Attempt 2: The full version of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4ESoJZfDOayX"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/combined_dataset.csv', engine='python')\n",
    "df_pos = df[df['Sentiment']=='positive']\n",
    "df_neg = df[df['Sentiment']=='negative']\n",
    "df = pd.concat([df_pos, df_neg])\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwuDdIN8UxoX",
    "outputId": "c94184b4-2c89-4744-b03a-d94426a48ccb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71239, 2)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sent_changer(sentiment):\n",
    "    if sentiment == 'positive':\n",
    "        x = 1\n",
    "    else:\n",
    "        x = 0\n",
    "    return x\n",
    "sentiments = df['Sentiment'].apply(sent_changer)\n",
    "\n",
    "Le = LabelEncoder()\n",
    "\n",
    "y = Le.fit_transform(df['Sentiment'])\n",
    "y = to_categorical(sentiments, 2)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "wVj1uial8LkE"
   },
   "outputs": [],
   "source": [
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "tokenizer.fit_on_texts(df['Review'])\n",
    "\n",
    "X = tokenizer.texts_to_sequences(df['Review'])\n",
    "X = pad_sequences(X, maxlen=max_len)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "G-_Me65uNg5f"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3lgviblNiti",
    "outputId": "c622a20f-1d89-455d-f68a-adb9c473dc9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 200)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 15)                12960     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 32        \n",
      "=================================================================\n",
      "Total params: 1,012,992\n",
      "Trainable params: 1,012,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 200))\n",
    "model.add(LSTM(15, dropout=0.3))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), 'accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W7CmbtdaNlaF",
    "outputId": "2bb4aa94-58e5-45af-8e8d-e94765ae143f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "446/446 [==============================] - 104s 228ms/step - loss: 0.4533 - precision_2: 0.8483 - recall_2: 0.8481 - accuracy: 0.8480 - val_loss: 0.4063 - val_precision_2: 0.8593 - val_recall_2: 0.8593 - val_accuracy: 0.8593\n",
      "Epoch 2/3\n",
      "446/446 [==============================] - 101s 227ms/step - loss: 0.3980 - precision_2: 0.8588 - recall_2: 0.8588 - accuracy: 0.8588 - val_loss: 0.4122 - val_precision_2: 0.8593 - val_recall_2: 0.8593 - val_accuracy: 0.8593\n",
      "Epoch 3/3\n",
      "446/446 [==============================] - 101s 227ms/step - loss: 0.3794 - precision_2: 0.8577 - recall_2: 0.8578 - accuracy: 0.8577 - val_loss: 0.4243 - val_precision_2: 0.8593 - val_recall_2: 0.8594 - val_accuracy: 0.8593\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 3\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtVSm7mV3b8E",
    "outputId": "963a7573-42d7-4a84-943c-fae94c6c0c1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.8"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 0.8577 # values taken from the previous step after the last epoch\n",
    "recall = 0.8578 # same as precision\n",
    "f1_score = 2*precision*recall / (precision + recall)\n",
    "round(f1_score*100, 1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
